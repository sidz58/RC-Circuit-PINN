{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Back at it!**\n",
    "Welcome back to your PINN project! \n",
    "\n",
    "*What we have acheived till now:*\n",
    "*  Made an input ramp function with full flexibility\n",
    "*  Made a **simple** PINN with input of time, to getdesirable results.\n",
    "*  Applied hyperarameter tuning to find the best hyperparameters for our task\n",
    "\n",
    "*What we aim to do now:*\n",
    "*  Build the next level of PINN with input of Voltage: \n",
    "    1.   Use gekko to collect output of capacitor, for different values of maximum amplitude of input voltage\n",
    "    2.   Now, input parameter to the PINN will be {time, amplitude(anything within a given range specified)}\n",
    "    3.   The idea is that we want to minimise the use of the ODE solver and allow the PINN to give output standalone!\n",
    "*  Apply the same process of hyperparamter tuning\n",
    "\n",
    "\n",
    "Change in PINN taking in 2 inputs\n",
    "every time points gives one output from PINN. \n",
    "Time-Max_amplitude pairs made to extract output\n",
    "\n",
    "Loss calculated for each row and added together\n",
    "\n",
    "We are not calculating derivative loss, just normal boundary loss and physics loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:43:54.051691Z",
     "iopub.status.busy": "2024-10-10T03:43:54.050934Z",
     "iopub.status.idle": "2024-10-10T03:44:18.974531Z",
     "shell.execute_reply": "2024-10-10T03:44:18.973387Z",
     "shell.execute_reply.started": "2024-10-10T03:43:54.051629Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gekko\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:18.977480Z",
     "iopub.status.busy": "2024-10-10T03:44:18.977050Z",
     "iopub.status.idle": "2024-10-10T03:44:23.106432Z",
     "shell.execute_reply": "2024-10-10T03:44:23.105625Z",
     "shell.execute_reply.started": "2024-10-10T03:44:18.977434Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from ramp_input import make_ramp_adv\n",
    "from gekko import GEKKO\n",
    "# import optuna\n",
    "# from optuna.trial import TrialState\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "\n",
    "# to account for fixed parameters in objective function:\n",
    "from functools import partial\n",
    "\n",
    "# if torch.cuda.is_available:\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     device = 'cpu'\n",
    "device = torch.device('cpu')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "        This is the making of a ramp function, only for the kaggle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:23.108318Z",
     "iopub.status.busy": "2024-10-10T03:44:23.107743Z",
     "iopub.status.idle": "2024-10-10T03:44:23.117990Z",
     "shell.execute_reply": "2024-10-10T03:44:23.117095Z",
     "shell.execute_reply.started": "2024-10-10T03:44:23.108272Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ramp_adv(time_points, T, t_rise, t_fall, delay, amplitude, last, repetitions):\n",
    "    '''\n",
    "    time_points = number of points per time period\n",
    "    T = time period\n",
    "    t_rise & t_fall = RATE of rise per unit time and rate for fall respectively\n",
    "    delay = input delay\n",
    "    repetitions = how many times you will repeat the input\n",
    "\n",
    "    Returns: output ramp function (y) and timespace(n) to plot\n",
    "    '''\n",
    "    y = []\n",
    "    n = np.linspace(0, repetitions * T, repetitions * time_points + 1)\n",
    "    resolution = int(time_points / T)\n",
    "    rise = t_rise / resolution\n",
    "    fall = t_fall / resolution\n",
    "    rise_steps = 0\n",
    "    \n",
    "    # delay (zero values)\n",
    "    for i in range(resolution * delay):\n",
    "        y.append(0)\n",
    "    \n",
    "    # up-ramp values\n",
    "    for i in range((T - delay) * resolution):\n",
    "        if rise * i > amplitude:\n",
    "            break\n",
    "        y.append(rise * i)\n",
    "        rise_steps += 1\n",
    "    \n",
    "    # amplitude-hold values\n",
    "    for i in range(last * resolution - rise_steps - int(amplitude // fall) - delay * resolution ):\n",
    "        y.append(amplitude)\n",
    "    \n",
    "    # down-ramp values\n",
    "    for i in range(int(amplitude // fall)+1):\n",
    "        y.append(amplitude - fall * i)\n",
    "    \n",
    "    # Append zeros to y to match the length of n\n",
    "    y += [0] * (time_points - len(y))\n",
    "\n",
    "    y_repeated = y * repetitions\n",
    "    y_repeated.append(0) #adds one term at the end that makes sure the sizes are matched between n and y_repeated\n",
    "\n",
    "    return y_repeated, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:23.120332Z",
     "iopub.status.busy": "2024-10-10T03:44:23.120048Z",
     "iopub.status.idle": "2024-10-10T03:44:23.132363Z",
     "shell.execute_reply": "2024-10-10T03:44:23.131530Z",
     "shell.execute_reply.started": "2024-10-10T03:44:23.120302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making dictionaries for passing into the final function\n",
    "\n",
    "# For hyperparameter otimisation we need to define a range of hyper parameters (among which Hyperopt will choose)\n",
    "\n",
    "# Dict 1: Value of parameters to BUILD the ramp input function: CONSTANT\n",
    "ramp_dict = { \n",
    "    \"T\": 40, # Time period in seconds\n",
    "    \"time_points\": 400, # The resolution of each time period: for example, 400 values of Voltage in 40 seconds. Useful in making the linear timespace\n",
    "    \"delay\": 0, # The input delay of ramp input in seconds\n",
    "    \"t_rise\": 0.5, # the rate of rise of ramp input\n",
    "    \"t_fall\": 0.2, # the rate of fall of ramp input\n",
    "    \n",
    "    \"last\": 35, # the point of termination of ramp input in seconds, after which Vin = 0\n",
    "    \"repetitions\": 2, # the repetitions for periodic input function\n",
    "    \n",
    "    # define the range of maximum amplitudes demanded, for which ramp inputs, Vinput can be stacked. \n",
    "    \"amp_low\": 1, \n",
    "    \"amp_high\": 5\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 2: Value of Resistor and capacitor in series R-C circuit\n",
    "lumped_elements = {\n",
    "    \"R\" : 5,\n",
    "    \"C\" : 1\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 3: Initial conditions for ODE solver. INPUT TO ODE SOLVER (GEKKO)\n",
    "initial_conditions = {\n",
    "    \"Vc\": 5.0,\n",
    "    \"dvdt\": 0.0\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 4: List of the hyperparameters for training process: TO BE OPTIMISED USING Bayesian Optimisation\n",
    "\n",
    "# PARAMETER SPACE:\n",
    "train_dict = {\n",
    "    \n",
    "    # Weights to the loss function\n",
    "    \"lambda_boundary\": hp.uniform(\"lambda_boundary\", 0.0, 1.0), # Contribution of the boundaries Vc[0] and Vc[-1] to the loss function\n",
    "    \n",
    "    \"lambda_physics\": hp.uniform(\"lambda_physics\", 0.0, 1.0), # Contribution of the physics loss to the loss function\n",
    "    \n",
    "    \"physics_points\": hp.quniform(\"physics_points\", 100, 200, 1), # Number of points where the physics loss is evaluated\n",
    "    # remember: quniform gives float output by default, so we cast it into integer before using it!\n",
    "    \n",
    "    \"lambda_deriv\": 0, # Contribution of the boundary dvdt[0] to the loss function\n",
    "\n",
    "    \"lr\": hp.uniform(\"lr\", 0.0001, 0.01),\n",
    "    \n",
    "    \"epochs\": hp.choice(\"epochs\", [20001, 25001, 30001, 35001, 40001]), # Number of epochs\n",
    "    \n",
    "    \"n_hidden\": hp.quniform(\"n_hidden\", 20, 40, 1),\n",
    "    \"n_layers\": hp.quniform(\"n_layers\", 4, 10, 1),\n",
    "    # typecast the above 2 parameters into INT before using\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:23.133527Z",
     "iopub.status.busy": "2024-10-10T03:44:23.133264Z",
     "iopub.status.idle": "2024-10-10T03:44:23.145458Z",
     "shell.execute_reply": "2024-10-10T03:44:23.144683Z",
     "shell.execute_reply.started": "2024-10-10T03:44:23.133498Z"
    }
   },
   "outputs": [],
   "source": [
    "def stack_Vin(ramp_dict):\n",
    "    \n",
    "    '''This function repeatedly calls the \"make_ramp\" function and then stacks the output from each.\n",
    "        Returns: stacked v_in data and n(timespace)'''\n",
    "    \n",
    "    repetitions = ramp_dict[\"repetitions\"]\n",
    "    time_points = ramp_dict[\"time_points\"]\n",
    "    T = ramp_dict[\"T\"]\n",
    "    t_rise = ramp_dict[\"t_rise\"]\n",
    "    t_fall = ramp_dict[\"t_fall\"]\n",
    "    amp_low = ramp_dict[\"amp_low\"]\n",
    "    amp_high = ramp_dict[\"amp_high\"]\n",
    "    last = ramp_dict[\"last\"]\n",
    "    delay = ramp_dict[\"delay\"]\n",
    "    \n",
    "    # Initialize v_input_data as an empty array for stacking\n",
    "    v_input_stacked = np.zeros((1, repetitions*time_points+1))  # this is number of timepoints, to define the correct dimensions of the stacked array\n",
    "\n",
    "    # Loop to create ramp inputs and concatenate along axis 0\n",
    "    # since loop cannot iterate in float values, we iterate it in the following way: we want a step of 0.1, hence multiply and divide by 10 for this effect\n",
    "    for i in range(10*amp_low, 10*amp_high + 1, 1):  \n",
    "        y, n = make_ramp_adv(time_points, T, t_rise, t_rise, delay, i/10, last, repetitions)\n",
    "        y = np.expand_dims(np.array(y), axis=0)  # Shape (1, 801)\n",
    "        v_input_stacked = np.concatenate((v_input_stacked, y), axis=0)  # Concatenate along axis 0\n",
    "\n",
    "    v_input_data = np.delete(v_input_stacked, 0, axis = 0) # the first row is 'zeroes', so delete it\n",
    "\n",
    "    return v_input_data, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:23.147007Z",
     "iopub.status.busy": "2024-10-10T03:44:23.146721Z",
     "iopub.status.idle": "2024-10-10T03:44:23.161797Z",
     "shell.execute_reply": "2024-10-10T03:44:23.160916Z",
     "shell.execute_reply.started": "2024-10-10T03:44:23.146975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a function that can be called repeatedly, that will stack our ground truth for every voltage input\n",
    "\n",
    "# Assume the voltage_input for one is passed in as input.\n",
    "def solve_ode(ramp_dict, initial_conditions, lumped_elements, Vin_ramp, n, plot = False):\n",
    "    # lets find a differential equation for SERIES R C circuit to determine the voltage\n",
    "\n",
    "    ''' Pre-defined differential equation solved: \n",
    "        Input: ramp function parameters, initial conditions, Value of resistor and capacitor, input ramp voltage, n for timespace\n",
    "        Returns: Voltage across capacitor, derivative of the same, ramp input, linear time space for plotting'''\n",
    "\n",
    "    \n",
    "    m = GEKKO()\n",
    "\n",
    "    # Getting the ramp function\n",
    "    m.time = n\n",
    "    \n",
    "    # make it as parameters to gekko\n",
    "    Vin = m.Param(value = Vin_ramp)\n",
    "    \n",
    "    # make variables here, and put their initial values\n",
    "    Vc = m.Var(initial_conditions[\"Vc\"]) \n",
    "    dvdt = m.Var(initial_conditions[\"dvdt\"])\n",
    "\n",
    "    R = lumped_elements[\"R\"]\n",
    "    C = lumped_elements[\"C\"]\n",
    "    \n",
    "    # make equation\n",
    "    m.Equation(dvdt + Vc/(R*C) == Vin/R*C)\n",
    "    m.Equation(Vc.dt()==dvdt)\n",
    "    #solve the equation\n",
    "    m.options.IMODE = 4\n",
    "    m.solve(disp = False) # if true, then a lot of things will be displayed\n",
    "    \n",
    "    DVDT = dvdt.value\n",
    "    time_space = m.time\n",
    "    \n",
    "    # plot the results\n",
    "    if plot:\n",
    "        plt.plot(m.time,Vin_ramp,'g:',label='Vin(t)')\n",
    "        plt.plot(m.time,Vc,'b-',label='Vc(t)')\n",
    "        plt.plot(m.time, DVDT, 'r--', label='d(Vc(t))/dt')\n",
    "        plt.ylabel('Vc(t)')\n",
    "        plt.xlabel('time')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    return Vc, DVDT, Vin_ramp, time_space\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# make the function that calls the above function, and then concatenates and returns the output for us\n",
    "\n",
    "def stack_solve_Vc(ramp_dict, initial_conditions, lumped_elements, Vin_data, n, plot = False):\n",
    "    \n",
    "    repetitions = ramp_dict[\"repetitions\"]\n",
    "    time_points = ramp_dict[\"time_points\"]\n",
    "    \n",
    "    stacked_ode = np.zeros((1, repetitions*time_points+1))\n",
    "    stacked_ode2 = np.zeros((1, repetitions*time_points+1))\n",
    "    for Vin in Vin_data:\n",
    "        \n",
    "        Vc, DVDT, _, _ = solve_ode(ramp_dict, initial_conditions, lumped_elements, Vin, n, plot = False)\n",
    "        \n",
    "        Vc = np.expand_dims(Vc, axis = 0)\n",
    "        stacked_ode = np.concatenate((stacked_ode, Vc), axis = 0)\n",
    "        DVDT = np.expand_dims(DVDT, axis = 0)\n",
    "        stacked_ode2 = np.concatenate((stacked_ode2, DVDT), axis = 0)\n",
    "        \n",
    "    stacked_Vc = np.delete(stacked_ode, 0, axis = 0)\n",
    "    stacked_dvdt = np.delete(stacked_ode2,0, axis = 0)\n",
    "    \n",
    "    return stacked_Vc, stacked_dvdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:44:51.110005Z",
     "iopub.status.busy": "2024-10-10T03:44:51.109599Z",
     "iopub.status.idle": "2024-10-10T03:48:27.240460Z",
     "shell.execute_reply": "2024-10-10T03:48:27.239457Z",
     "shell.execute_reply.started": "2024-10-10T03:44:51.109969Z"
    }
   },
   "outputs": [],
   "source": [
    "v_input_data, n = stack_Vin(ramp_dict)\n",
    "stacked_Vc, stacked_dvdt = stack_solve_Vc(ramp_dict, initial_conditions, lumped_elements, v_input_data, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:48:27.242844Z",
     "iopub.status.busy": "2024-10-10T03:48:27.242496Z",
     "iopub.status.idle": "2024-10-10T03:48:27.541555Z",
     "shell.execute_reply": "2024-10-10T03:48:27.540582Z",
     "shell.execute_reply.started": "2024-10-10T03:48:27.242809Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1)\n",
    "plt.plot(n, v_input_data[40])\n",
    "plt.plot(n, stacked_Vc[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a complete pipeline to show the model's flexibility:\n",
    "### Objectives: \n",
    "1. Incorporate the initial conditions into the model.\n",
    "2. Include the flexibility of your ramp input function, add the params (make a dictionary)\n",
    "3. Display the ground truth values from GEKKO as a part of training process\n",
    "\n",
    "Path: \n",
    "Ramp input -> GEKKO -> Voltage curve -> Model_train -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:48:27.543721Z",
     "iopub.status.busy": "2024-10-10T03:48:27.543299Z",
     "iopub.status.idle": "2024-10-10T03:48:27.551752Z",
     "shell.execute_reply": "2024-10-10T03:48:27.550764Z",
     "shell.execute_reply.started": "2024-10-10T03:48:27.543674Z"
    }
   },
   "outputs": [],
   "source": [
    "# the definition of the PINN remains the same, because the N_inputs tab previously held value = 1, now it will hold value 2.\n",
    "# basically as our model becomes larger, with more parameters, we can keep on increasing the number of inputs\n",
    "\n",
    "# Number of inputs: number of features and values to be considered in PINN and solving\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    \"\"\"Defines a standard fully-connected network in PyTorch.\n",
    "    Number of inputs, Number of outputs, Number of hidden inputs, Total layers\"\"\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(nn.Linear(N_INPUT, N_HIDDEN), activation())\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T03:48:27.554658Z",
     "iopub.status.busy": "2024-10-10T03:48:27.553955Z",
     "iopub.status.idle": "2024-10-10T03:48:27.562270Z",
     "shell.execute_reply": "2024-10-10T03:48:27.561401Z",
     "shell.execute_reply.started": "2024-10-10T03:48:27.554611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract the boundary values of all the stacked ground truth items\n",
    "def extract_boundaries(stacked_vc, stacked_dvdt):\n",
    "\n",
    "    '''This function is responsible for extracting the boundaries of the solved ODE equation\n",
    "        Shape of stacked_vc is: number of discrete amplitudes, number of timepoints\n",
    "        Returned datatype: Dictionary\n",
    "        These boundary values will be used in the Loss function of the PINN'''\n",
    "    \n",
    "    boundaries = {\n",
    "        \"u_last\" : stacked_vc[:,-1],\n",
    "        \"u_first\" : stacked_vc[:,0],\n",
    "        \"du_first\" : stacked_dvdt[:, 0],\n",
    "        \"du_last\" : stacked_dvdt[:, -1]\n",
    "    }\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T17:38:37.148463Z",
     "iopub.status.busy": "2024-10-09T17:38:37.147631Z",
     "iopub.status.idle": "2024-10-09T17:38:37.154410Z",
     "shell.execute_reply": "2024-10-09T17:38:37.153458Z",
     "shell.execute_reply.started": "2024-10-09T17:38:37.148420Z"
    }
   },
   "outputs": [],
   "source": [
    "# in my earlier implementation, we had a single row which was interpolated to calculate the physics loss\n",
    "# now we are dealing with multiple input functions at once so we need a code to interpolate them all together\n",
    "\n",
    "def interpolate_multiple_rows(v_input, physics_points):\n",
    "    interpolated_inputs = []\n",
    "    \n",
    "    # Iterate over each row in v_input\n",
    "    for row in v_input:\n",
    "        # Interpolate each row\n",
    "        interpolated_row = F.interpolate(torch.tensor(row, dtype=torch.float32).view(1, 1, -1), size=physics_points).view(-1, 1)\n",
    "        # Enable gradients\n",
    "        interpolated_row.requires_grad_(True)\n",
    "        # Store the interpolated row\n",
    "        interpolated_inputs.append(interpolated_row)\n",
    "    \n",
    "    # Stack the rows back into a single tensor. If we don't do this, then they will appear as separate tensors\n",
    "    interpolated_inputs = torch.stack(interpolated_inputs)\n",
    "\n",
    "    return interpolated_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:05:04.352100Z",
     "iopub.status.busy": "2024-10-10T04:05:04.351672Z",
     "iopub.status.idle": "2024-10-10T04:05:04.373719Z",
     "shell.execute_reply": "2024-10-10T04:05:04.372778Z",
     "shell.execute_reply.started": "2024-10-10T04:05:04.352063Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(lr, lumped_elements, boundaries, v_input_data, stacked_vc, lambda_boundary, lambda_deriv, lambda_physics, epochs, physics_points, \n",
    "                n_hidden, n_layers, n_repetitions, time_period, time_points, amp_low, amp_high):\n",
    "\n",
    "    '''\n",
    "    Inputs: lr --> learning rate\n",
    "            Boundaries --> Final and initial values of capacitor voltage\n",
    "            v_input --> Input ramp function\n",
    "            Vc --> ground truth from GEKKO\n",
    "            lambda_boundary/deriv/physics --> contributory weights of the boundary loss, derivative boundary loss, and physics loss\n",
    "            epochs --> number of epochs\n",
    "            physics_points --> number of points for which physics loss is evaluated\n",
    "            n_hidden + n_layers --> definition of number of nodes per layer and number of layers in PINN model\n",
    "            n_repetitions --> number of repetitions of ramp input\n",
    "            time_period + time_points --> time period of ramp input in seconds and number of time_points per period\n",
    "            \n",
    "    Objective of function: Instantiating the PINN model; building the loss function with the mentioned weights; '''\n",
    "    \n",
    "    #torch.manual_seed(123)\n",
    "    # Extracting standard values from dictionaries\n",
    "    \n",
    "    R = lumped_elements[\"R\"]\n",
    "    C = lumped_elements[\"C\"]\n",
    "    u_first = boundaries[\"u_first\"] # these are arrays of boundary conditions for every case\n",
    "    u_last = boundaries[\"u_last\"]\n",
    "    du_first = boundaries[\"du_first\"]\n",
    "    du_last = boundaries[\"du_last\"]\n",
    "\n",
    "    # Define a fully connected network (FCN) for the PINN. 2 inputs include time and amplitude of our ramp input function\n",
    "    pinn = FCN(2, 1, n_hidden, n_layers)\n",
    "    pinn.to(device)\n",
    "    \n",
    "    # Define boundary points for the boundary loss (time points, not voltage values)\n",
    "    time_point_left = torch.tensor([0.0], dtype=torch.float32).view(-1, 1).requires_grad_(True)  \n",
    "    time_point_right = torch.tensor([time_points*n_repetitions], dtype=torch.float32).view(-1, 1).requires_grad_(True)  # the last value in the time series\n",
    "    time_point_left.to(device)\n",
    "    time_point_right.to(device)\n",
    "    \n",
    "    # Defining linear timespace with number of points = 'physics_points'; TO CALCULATE PHYSICS LOSS\n",
    "    t_physics = torch.linspace(0, time_period*n_repetitions, physics_points, dtype=torch.float32).view(-1, 1).to(device).requires_grad_(True)\n",
    "    \n",
    "    # Making V_input smaller in size to match number of physics points; and enabling grad. Call interpolate function\n",
    "    # v_input_interp = interpolate_multiple_rows(v_input_data, physics_points)\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimiser = torch.optim.Adam(pinn.parameters(), lr= lr)\n",
    "\n",
    "    \n",
    "    t_test = torch.linspace(0, time_period*n_repetitions, time_points*n_repetitions+1).view(-1,1).to(device)\n",
    "\n",
    "    # Converting the ground truth from the ODE solver into a tensor\n",
    "    u_exact = torch.tensor(stacked_vc).to(device) # exact solution(s) from GEKKO\n",
    "    \n",
    "    # making a range of amplitude for input to the PINN:\n",
    "    amplitude_range = torch.arange(amp_low, amp_high + 0.1, 0.1).view(-1, 1).to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    for i in range(epochs):\n",
    "        optimiser.zero_grad()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # We calculate loss for every row in the data, and we directly add them together\n",
    "        # Changes to PINN: we need to concatenate the time and the amplitude inputs.\n",
    "        \n",
    "        for row in range(v_input_data.shape[0]):\n",
    "            \n",
    "            v_input_row = v_input_data[row]  # Extract one row of v_input_data\n",
    "           \n",
    "            u_exact_row = u_exact[row]  # Corresponding ground truth\n",
    "         \n",
    "            amplitude_value = amplitude_range[row]\n",
    "            amplitude_value.to(device)\n",
    "            \n",
    "            # Interpolate the row for the physics loss\n",
    "            v_input_interp = F.interpolate(torch.tensor(v_input_row, dtype=torch.float32).view(1, 1, -1), size=physics_points).view(-1, 1).requires_grad_(True)\n",
    "            v_input_interp.to(device)\n",
    "            \n",
    "            # Physics inputs: concatenate time and amplitude. Extend the single amplitude value to make pairs of time and amp\n",
    "            time_amplitude_input = torch.cat([t_physics, amplitude_value.expand(physics_points, -1)], dim=1).to(device)\n",
    "            \n",
    "            \n",
    "            # Compute boundary loss: (predicted values from PINN - ground truth)^2\n",
    "            u_left = pinn(torch.cat([time_point_left, amplitude_value.view(1,1)], dim = 1)).to(device)  # at t = 0\n",
    "            \n",
    "            loss1a = (torch.squeeze(u_left) - u_first[row])**2  \n",
    "            loss1a.to(device)\n",
    "\n",
    "            u_right = pinn(torch.cat([time_point_right, amplitude_value.view(1,1)], dim = 1)).to(device)  # at t = end\n",
    "            loss1b = (torch.squeeze(u_right) - u_last[row])**2  \n",
    "            loss1b.to(device)\n",
    "\n",
    "            # loss for time derivative at the initial condition\n",
    "#             dudt_left = torch.autograd.grad(u_left, time_point_left, torch.ones_like(u_left), create_graph=True)[0]\n",
    "#             loss_deriv = (torch.squeeze(dudt_left) - du_first)**2\n",
    "\n",
    "            # Physics loss: differential equation with input incorporated. Loss calculated at multiple points. Thus we need to expand the \n",
    "            # amplitude value across the time points, so that we have pairs of time vs max_amplitude(same for all time points)\n",
    "                          \n",
    "            u_physics = pinn(time_amplitude_input)  # Evaluate PINN at physics points\n",
    "            u_physics.to(device)\n",
    "            dudt_physics = torch.autograd.grad(u_physics, t_physics, torch.ones_like(u_physics), create_graph=True)[0]\n",
    "            dudt_physics.to(device)\n",
    "            loss_physics = torch.mean((dudt_physics + u_physics / (R * C) - v_input_interp / (R * C))**2).to(device)\n",
    "\n",
    "            # Total loss\n",
    "            row_loss = lambda_boundary * (loss1a + loss1b) + lambda_physics * loss_physics\n",
    "            row_loss.to(device)\n",
    "            total_loss += row_loss\n",
    "            total_loss.to(device)\n",
    "            \n",
    "            \n",
    "        total_loss.backward()  \n",
    "        optimiser.step()  \n",
    "        \n",
    "        # Plot the result during training\n",
    "#         if i % 10000 == 0:\n",
    "#             u_test = pinn(t_test).detach()\n",
    "#             plt.figure(figsize=(6, 2.5))\n",
    "#             plt.scatter(t_physics.detach()[:, 0], torch.zeros_like(t_physics)[:, 0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
    "#             plt.scatter(time_point_left.detach()[:, 0], torch.zeros_like(time_point_left)[:, 0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
    "#             plt.plot(t_test[:, 0], u_exact[:, 0], label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "#             plt.plot(t_test[:, 0], u_test[:, 0], label=\"PINN solution\", color=\"tab:green\")\n",
    "#             plt.title(f\"Training step {i}\")\n",
    "#             plt.legend()\n",
    "#             plt.show()\n",
    "\n",
    "    return total_loss, pinn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:21:55.520765Z",
     "iopub.status.busy": "2024-10-10T04:21:55.520080Z",
     "iopub.status.idle": "2024-10-10T04:21:55.536966Z",
     "shell.execute_reply": "2024-10-10T04:21:55.535978Z",
     "shell.execute_reply.started": "2024-10-10T04:21:55.520726Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(lr, lumped_elements, boundaries, v_input_data, stacked_vc, lambda_boundary, lambda_deriv, lambda_physics, epochs, physics_points, \n",
    "                n_hidden, n_layers, n_repetitions, time_period, time_points, amp_low, amp_high):\n",
    "\n",
    "    R = lumped_elements[\"R\"]\n",
    "    C = lumped_elements[\"C\"]\n",
    "    u_first = boundaries[\"u_first\"]\n",
    "    u_last = boundaries[\"u_last\"]\n",
    "\n",
    "    # Define the fully connected network (FCN)\n",
    "    pinn = FCN(2, 1, n_hidden, n_layers).to(device)\n",
    "\n",
    "    # Define boundary points for the boundary loss\n",
    "    time_point_left = torch.tensor([0.0], dtype=torch.float32).view(-1, 1).to(device).requires_grad_(True)\n",
    "    time_point_right = torch.tensor([time_points * n_repetitions], dtype=torch.float32).view(-1, 1).to(device).requires_grad_(True)\n",
    "\n",
    "    # Define linear time space for physics loss\n",
    "    t_physics = torch.linspace(0, time_period * n_repetitions, physics_points, dtype=torch.float32).view(-1, 1).to(device).requires_grad_(True)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimiser = torch.optim.Adam(pinn.parameters(), lr=lr)\n",
    "\n",
    "    # Convert the ground truth from the ODE solver into a tensor\n",
    "    u_exact = torch.tensor(stacked_vc).to(device)\n",
    "\n",
    "    # Create a range of amplitudes for input to the PINN\n",
    "    amplitude_range = torch.arange(amp_low, amp_high + 0.1, 0.1).view(-1, 1).to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(epochs):\n",
    "        optimiser.zero_grad()\n",
    "        total_loss = 0\n",
    "\n",
    "        for row in range(v_input_data.shape[0]):\n",
    "            v_input_row = v_input_data[row]\n",
    "            u_exact_row = u_exact[row]\n",
    "\n",
    "            amplitude_value = amplitude_range[row].to(device)\n",
    "\n",
    "            # Interpolate the row for the physics loss\n",
    "            v_input_interp = F.interpolate(torch.tensor(v_input_row, dtype=torch.float32).view(1, 1, -1).to(device), size=physics_points).view(-1, 1).requires_grad_(True)\n",
    "\n",
    "            # Create time and amplitude input pairs\n",
    "            time_amplitude_input = torch.cat([t_physics, amplitude_value.expand(physics_points, -1)], dim=1).to(device)\n",
    "\n",
    "            # Compute boundary loss\n",
    "            u_left = pinn(torch.cat([time_point_left, amplitude_value.view(1, 1)], dim=1)).to(device)\n",
    "            loss1a = (torch.squeeze(u_left) - u_first[row]) ** 2\n",
    "\n",
    "            u_right = pinn(torch.cat([time_point_right, amplitude_value.view(1, 1)], dim=1)).to(device)\n",
    "            loss1b = (torch.squeeze(u_right) - u_last[row]) ** 2\n",
    "\n",
    "            # Physics loss\n",
    "            u_physics = pinn(time_amplitude_input).to(device)\n",
    "            dudt_physics = torch.autograd.grad(u_physics, t_physics, torch.ones_like(u_physics), create_graph=True)[0].to(device)\n",
    "            loss_physics = torch.mean((dudt_physics + u_physics / (R * C) - v_input_interp / (R * C)) ** 2).to(device)\n",
    "\n",
    "            # Total loss\n",
    "            row_loss = lambda_boundary * (loss1a + loss1b) + lambda_physics * loss_physics\n",
    "            total_loss += row_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    return total_loss, pinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:21:56.877273Z",
     "iopub.status.busy": "2024-10-10T04:21:56.876915Z",
     "iopub.status.idle": "2024-10-10T04:21:56.882058Z",
     "shell.execute_reply": "2024-10-10T04:21:56.881173Z",
     "shell.execute_reply.started": "2024-10-10T04:21:56.877240Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(str):\n",
    "\n",
    "    '''Save the model with annotation of your choice, to your default folder'''\n",
    "    output_model_file = '/kaggle/working/RC_PINN_'+str+'.pt'\n",
    "    \n",
    "    model_to_save = FCN\n",
    "    torch.save(model_to_save, output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:21:57.485143Z",
     "iopub.status.busy": "2024-10-10T04:21:57.484787Z",
     "iopub.status.idle": "2024-10-10T04:21:57.492533Z",
     "shell.execute_reply": "2024-10-10T04:21:57.491678Z",
     "shell.execute_reply.started": "2024-10-10T04:21:57.485108Z"
    }
   },
   "outputs": [],
   "source": [
    "def RAW_solve_train_objective(train_dict, ramp_dict, initial_conditions, lumped_elements, v_input_data, stacked_Vc):\n",
    "\n",
    "    '''An end-to-end function for deployment:\n",
    "    Inputs: ramp_dict --> parameters to define the input ramp function\n",
    "            initial_conditions --> initial conditions for solving the ODE equation\n",
    "            train_dict --> hyperparameters for the training process\n",
    "            \n",
    "    returns: predicted voltage across capacitor'''\n",
    "    \n",
    "#     # stacked input voltage\n",
    "#     v_input_data, n = stack_Vin(ramp_dict)\n",
    "    \n",
    "#     # stacked outout capacitor voltage\n",
    "#     stacked_Vc, stacked_dvdt = stack_solve_Vc(ramp_dict, initial_conditions, lumped_elements, v_input_data, n)\n",
    "    \n",
    "    # extract boundaries to compute the boundary loss in 'train_model'\n",
    "    boundaries = extract_boundaries(stacked_Vc, stacked_dvdt)\n",
    "\n",
    "    # compute and retrieve the predicted values from the training process\n",
    "    loss, pinn = train_model(train_dict[\"lr\"], lumped_elements, boundaries, v_input_data, stacked_Vc, train_dict[\"lambda_boundary\"], train_dict[\"lambda_deriv\"], \n",
    "                                     train_dict[\"lambda_physics\"],train_dict[\"epochs\"], int(train_dict[\"physics_points\"]), int(train_dict[\"n_hidden\"]), int(train_dict[\"n_layers\"]), \n",
    "                                     ramp_dict[\"repetitions\"], ramp_dict[\"T\"], ramp_dict[\"time_points\"], ramp_dict[\"amp_low\"], ramp_dict[\"amp_high\"])\n",
    "\n",
    "    # save the model\n",
    "    #save_model(str)\n",
    "    return {'loss': loss,\n",
    "            'status': STATUS_OK,\n",
    "            'model': pinn,\n",
    "            'params': train_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:21:58.174268Z",
     "iopub.status.busy": "2024-10-10T04:21:58.172417Z",
     "iopub.status.idle": "2024-10-10T04:21:58.178498Z",
     "shell.execute_reply": "2024-10-10T04:21:58.177667Z",
     "shell.execute_reply.started": "2024-10-10T04:21:58.174221Z"
    }
   },
   "outputs": [],
   "source": [
    "save_train_objective = partial(RAW_solve_train_objective, \n",
    "                              ramp_dict = ramp_dict,\n",
    "                              initial_conditions = initial_conditions,\n",
    "                              lumped_elements = lumped_elements,\n",
    "                              v_input_data = v_input_data,\n",
    "                              stacked_Vc = stacked_Vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T04:21:58.563778Z",
     "iopub.status.busy": "2024-10-10T04:21:58.563428Z"
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=save_train_objective,\n",
    "    space=train_dict,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:10:39.458881Z",
     "iopub.status.busy": "2024-10-09T09:10:39.458491Z",
     "iopub.status.idle": "2024-10-09T09:10:39.466831Z",
     "shell.execute_reply": "2024-10-09T09:10:39.465761Z",
     "shell.execute_reply.started": "2024-10-09T09:10:39.458846Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model('level_2_attempt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:12:32.929017Z",
     "iopub.status.busy": "2024-10-09T09:12:32.928614Z",
     "iopub.status.idle": "2024-10-09T09:12:32.935114Z",
     "shell.execute_reply": "2024-10-09T09:12:32.934041Z",
     "shell.execute_reply.started": "2024-10-09T09:12:32.928982Z"
    }
   },
   "outputs": [],
   "source": [
    "strin = 'level_2_attempt3'\n",
    "try: \n",
    "\tgeeky_file = open('best_parameters'+ strin +'.txt', 'a') \n",
    "\tgeeky_file.write(str(best_params)) \n",
    "\tgeeky_file.close() \n",
    "\n",
    "except: \n",
    "\tprint(\"Unable to append to file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:18:26.775604Z",
     "iopub.status.busy": "2024-10-09T09:18:26.775190Z",
     "iopub.status.idle": "2024-10-09T09:18:26.780836Z",
     "shell.execute_reply": "2024-10-09T09:18:26.779906Z",
     "shell.execute_reply.started": "2024-10-09T09:18:26.775569Z"
    }
   },
   "outputs": [],
   "source": [
    "try: print(best_params)\n",
    "\n",
    "except: print('best_params not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
