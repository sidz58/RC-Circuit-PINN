{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:02.631822Z",
     "iopub.status.busy": "2024-10-09T08:44:02.631058Z",
     "iopub.status.idle": "2024-10-09T08:44:26.069329Z",
     "shell.execute_reply": "2024-10-09T08:44:26.068145Z",
     "shell.execute_reply.started": "2024-10-09T08:44:02.631773Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gekko\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:26.071760Z",
     "iopub.status.busy": "2024-10-09T08:44:26.071421Z",
     "iopub.status.idle": "2024-10-09T08:44:28.716763Z",
     "shell.execute_reply": "2024-10-09T08:44:28.715985Z",
     "shell.execute_reply.started": "2024-10-09T08:44:26.071725Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from ramp_input import make_ramp_adv\n",
    "from gekko import GEKKO\n",
    "# import optuna\n",
    "# from optuna.trial import TrialState\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "\n",
    "# to account for fixed parameters in objective function:\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "        This is the making of a ramp function, only for the kaggle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:28.718222Z",
     "iopub.status.busy": "2024-10-09T08:44:28.717797Z",
     "iopub.status.idle": "2024-10-09T08:44:28.729780Z",
     "shell.execute_reply": "2024-10-09T08:44:28.728831Z",
     "shell.execute_reply.started": "2024-10-09T08:44:28.718190Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_ramp_adv(time_points, T, t_rise, t_fall, delay, amplitude, last, repetitions):\n",
    "    '''\n",
    "    time_points = number of points per time period\n",
    "    T = time period\n",
    "    t_rise & t_fall = RATE of rise per unit time and rate for fall respectively\n",
    "    delay = input delay\n",
    "    repetitions = how many times you will repeat the input\n",
    "\n",
    "    Returns: output ramp function (y) and timespace(n) to plot\n",
    "    '''\n",
    "    y = []\n",
    "    n = np.linspace(0, repetitions * T, repetitions * time_points + 1)\n",
    "    resolution = int(time_points / T)\n",
    "    rise = t_rise / resolution\n",
    "    fall = t_fall / resolution\n",
    "    rise_steps = 0\n",
    "    \n",
    "    # delay (zero values)\n",
    "    for i in range(resolution * delay):\n",
    "        y.append(0)\n",
    "    \n",
    "    # up-ramp values\n",
    "    for i in range((T - delay) * resolution):\n",
    "        if rise * i > amplitude:\n",
    "            break\n",
    "        y.append(rise * i)\n",
    "        rise_steps += 1\n",
    "    \n",
    "    # amplitude-hold values\n",
    "    for i in range(last * resolution - rise_steps - int(amplitude // fall) - delay * resolution ):\n",
    "        y.append(amplitude)\n",
    "    \n",
    "    # down-ramp values\n",
    "    for i in range(int(amplitude // fall)+1):\n",
    "        y.append(amplitude - fall * i)\n",
    "    \n",
    "    # Append zeros to y to match the length of n\n",
    "    y += [0] * (time_points - len(y))\n",
    "\n",
    "    y_repeated = y * repetitions\n",
    "    y_repeated.append(0) #adds one term at the end that makes sure the sizes are matched between n and y_repeated\n",
    "\n",
    "    return y_repeated, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a complete pipeline to show the model's flexibility:\n",
    "### Objectives: \n",
    "1. Incorporate the initial conditions into the model.\n",
    "2. Include the flexibility of your ramp input function, add the params (make a dictionary)\n",
    "3. Display the ground truth values from GEKKO as a part of training process\n",
    "\n",
    "Path: \n",
    "Ramp input -> GEKKO -> Voltage curve -> Model_train -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dictionaries for passing into the final function\n",
    "\n",
    "# For hyperparameter otimisation we need to define a range of hyper parameters (among which Hyperopt will choose)\n",
    "\n",
    "# Dict 1: Value of parameters to BUILD the ramp input function: CONSTANT\n",
    "ramp_dict = { \n",
    "    \"T\": 40, # Time period in seconds\n",
    "    \"time_points\": 400, # The resolution of each time period: for example, 400 values of Voltage in 40 seconds. Useful in making the linear timespace\n",
    "    \"delay\": 0, # The input delay of ramp input in seconds\n",
    "    \"t_rise\": 0.5, # the rate of rise of ramp input\n",
    "    \"t_fall\": 0.2, # the rate of fall of ramp input\n",
    "    \"amplitude\": 2, # Maximum amplitude of ramp input\n",
    "    \"last\": 35, # the point of termination of ramp input in seconds, after which Vin = 0\n",
    "    \"repetitions\": 2 # the repetitions for periodic input function\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 2: Value of Resistor and capacitor in series R-C circuit\n",
    "lumped_elements = {\n",
    "    \"R\" : 5,\n",
    "    \"C\" : 1\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 3: Initial conditions for ODE solver. INPUT TO ODE SOLVER (GEKKO)\n",
    "initial_conditions = {\n",
    "    \"Vc\": 5.0,\n",
    "    \"dvdt\": 0.0\n",
    "}\n",
    "\n",
    "\n",
    "# Dict 4: List of the hyperparameters for training process: TO BE OPTIMISED USING Bayesian Optimisation\n",
    "\n",
    "# PARAMETER SPACE:\n",
    "train_dict = {\n",
    "    \n",
    "    # Weights to the loss function\n",
    "    \"n_hidden\": hp.quniform(\"n_hidden\", 20, 40, 1),\n",
    "    \"n_layers\": hp.quniform(\"n_layers\", 4, 10, 1),\n",
    "    # typecast the above 2 parameters into INT before using\n",
    "    \n",
    "    \"lambda_boundary\": hp.uniform(\"lambda_boundary\", 0.0, 1.0), # Contribution of the boundaries Vc[0] and Vc[-1] to the loss function\n",
    "    \n",
    "    \"lambda_physics\": hp.uniform(\"lambda_physics\", 0.0, 1.0), # Contribution of the physics loss to the loss function\n",
    "    \n",
    "    \"lambda_deriv\": 0, # Contribution of the boundary dvdt[0] to the loss function\n",
    "\n",
    "    \"lr\": hp.uniform(\"lr\", 0.0001, 0.01),\n",
    "    \n",
    "    \"epochs\": hp.choice(\"epochs\", [20001, 25001, 30001, 35001, 40001]), # Number of epochs\n",
    "    \n",
    "    \n",
    "    \"physics_points\": hp.quniform(\"physics_points\", 100, 200, 1), # Number of points where the physics loss is evaluated\n",
    "    # remember: quniform gives float output by default, so we cast it into integer before using it!\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:28.744575Z",
     "iopub.status.busy": "2024-10-09T08:44:28.744244Z",
     "iopub.status.idle": "2024-10-09T08:44:28.755114Z",
     "shell.execute_reply": "2024-10-09T08:44:28.754364Z",
     "shell.execute_reply.started": "2024-10-09T08:44:28.744536Z"
    }
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    \"\"\"Defines a standard fully-connected network in PyTorch.\n",
    "    Number of inputs, Number of outputs, Number of hidden inputs, Total layers\"\"\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(nn.Linear(N_INPUT, N_HIDDEN), activation(),)\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:28.759123Z",
     "iopub.status.busy": "2024-10-09T08:44:28.756250Z",
     "iopub.status.idle": "2024-10-09T08:44:28.769423Z",
     "shell.execute_reply": "2024-10-09T08:44:28.768472Z",
     "shell.execute_reply.started": "2024-10-09T08:44:28.759090Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_ode(ramp_dict, initial_conditions, lumped_elements, plot = False):\n",
    "    # lets find a differential equation for SERIES R C circuit to determine the voltage\n",
    "\n",
    "    ''' Pre-defined differential equation solved: \n",
    "        Input: ramp function parameters, initial conditions, Value of resistor and capacitor\n",
    "        Returns: Voltage across capacitor, derivative of the same, ramp input, linear time space for plotting'''\n",
    "\n",
    "    \n",
    "    m = GEKKO()\n",
    "\n",
    "    # Getting the ramp function\n",
    "    Vin_ramp, m.time = make_ramp_adv(ramp_dict[\"time_points\"], ramp_dict[\"T\"], ramp_dict[\"t_rise\"], ramp_dict[\"t_fall\"], \n",
    "                                     ramp_dict[\"delay\"], ramp_dict[\"amplitude\"], ramp_dict[\"last\"], ramp_dict[\"repetitions\"])\n",
    "    \n",
    "    # make it as parameters to gekko\n",
    "    Vin = m.Param(value = Vin_ramp)\n",
    "    \n",
    "    # make variables here, and put their initial values\n",
    "    Vc = m.Var(initial_conditions[\"Vc\"]) \n",
    "    dvdt = m.Var(initial_conditions[\"dvdt\"])\n",
    "\n",
    "    R = lumped_elements[\"R\"]\n",
    "    C = lumped_elements[\"C\"]\n",
    "    \n",
    "    # make equation\n",
    "    m.Equation(dvdt + Vc/(R*C) == Vin/R*C)\n",
    "    m.Equation(Vc.dt()==dvdt)\n",
    "    #solve the equation\n",
    "    m.options.IMODE = 4\n",
    "    m.solve(disp = False) # if true, then a lot of things will be displayed\n",
    "    \n",
    "    DVDT = dvdt.value\n",
    "    time_space = m.time\n",
    "    \n",
    "    # plot the results\n",
    "    if plot:\n",
    "        plt.plot(m.time,Vin_ramp,'g:',label='Vin(t)')\n",
    "        plt.plot(m.time,Vc,'b-',label='Vc(t)')\n",
    "        plt.plot(m.time, DVDT, 'r--', label='d(Vc(t))/dt')\n",
    "        plt.ylabel('Vc(t)')\n",
    "        plt.xlabel('time')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    return Vc, DVDT, Vin_ramp, time_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:28.770997Z",
     "iopub.status.busy": "2024-10-09T08:44:28.770648Z",
     "iopub.status.idle": "2024-10-09T08:44:28.781616Z",
     "shell.execute_reply": "2024-10-09T08:44:28.780758Z",
     "shell.execute_reply.started": "2024-10-09T08:44:28.770957Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_boundaries(Vc, DVDT):\n",
    "\n",
    "    '''This function is responsible for extracting the boundaries of the solved ODE equation\n",
    "        Returned datatype: Dictionary\n",
    "        These boundary values will be used in the Loss function of the PINN'''\n",
    "    \n",
    "    boundaries = {\n",
    "        \"u_last\" : Vc[-1],\n",
    "        \"u_first\" : Vc[0],\n",
    "        \"du_first\" : DVDT[0],\n",
    "        \"du_last\" : DVDT[-1]\n",
    "    }\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:19:56.727690Z",
     "iopub.status.busy": "2024-10-09T09:19:56.727264Z",
     "iopub.status.idle": "2024-10-09T09:19:56.747439Z",
     "shell.execute_reply": "2024-10-09T09:19:56.746474Z",
     "shell.execute_reply.started": "2024-10-09T09:19:56.727653Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(lr, lumped_elements, boundaries, v_input, Vc, lambda_boundary, lambda_deriv, lambda_physics, epochs, physics_points, \n",
    "                n_hidden, n_layers, n_repetitions, time_period, time_points):\n",
    "\n",
    "    '''\n",
    "    Inputs: lr --> learning rate\n",
    "            Boundaries --> Final and initial values of capacitor voltage\n",
    "            v_input --> Input ramp function\n",
    "            Vc --> ground truth from GEKKO\n",
    "            lambda_boundary/deriv/physics --> contributory weights of the boundary loss, derivative boundary loss, and physics loss\n",
    "            epochs --> number of epochs\n",
    "            physics_points --> number of points for which physics loss is evaluated\n",
    "            n_hidden + n_layers --> definition of number of nodes per layer and number of layers in PINN model\n",
    "            n_repetitions --> number of repetitions of ramp input\n",
    "            time_period + time_points --> time period of ramp input in seconds and number of time_points per period\n",
    "            \n",
    "    Objective of function: Instantiating the PINN model; building the loss function with the mentioned weights; '''\n",
    "    \n",
    "    #torch.manual_seed(123)\n",
    "    # Extracting standard values from dictionaries\n",
    "    \n",
    "    R = lumped_elements[\"R\"]\n",
    "    C = lumped_elements[\"C\"]\n",
    "    u_first = boundaries[\"u_first\"]\n",
    "    u_last = boundaries[\"u_last\"]\n",
    "    du_first = boundaries[\"du_first\"]\n",
    "    du_last = boundaries[\"du_last\"]\n",
    "\n",
    "    # Define a fully connected network (FCN) for the PINN\n",
    "    pinn = FCN(1, 1, n_hidden, n_layers)\n",
    "    \n",
    "    # Define boundary points for the boundary loss (time points, not voltage values)\n",
    "    time_point_left = torch.tensor([0.0], dtype=torch.float32).view(-1, 1).requires_grad_(True)  \n",
    "    time_point_right = torch.tensor([time_points*n_repetitions], dtype=torch.float32).view(-1, 1).requires_grad_(True)  # the last value in the time series\n",
    "\n",
    "    \n",
    "    # Defining linear timespace with number of points = 'physics_points'; TO CALCULATE PHYSICS LOSS\n",
    "    t_physics = torch.linspace(0, time_period*n_repetitions, physics_points, dtype=torch.float32).view(-1, 1).requires_grad_(True)\n",
    "    \n",
    "    # Making V_input smaller in size to match number of physics points; and enabling grad\n",
    "    v_input_interp = F.interpolate(torch.tensor(v_input, dtype=torch.float32).view(1, 1, -1), size=physics_points).view(-1, 1).requires_grad_(True)\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimiser = torch.optim.Adam(pinn.parameters(), lr= lr)\n",
    "\n",
    "    \n",
    "    t_test = torch.linspace(0, time_period*n_repetitions, time_points*n_repetitions+1).view(-1,1)\n",
    "\n",
    "    # Converting the ground truth from the ODE solver into a tensor\n",
    "    u_exact = torch.tensor(Vc).view(-1,1)  # exact solution from GEKKO\n",
    "    \n",
    "    # Training loop\n",
    "    for i in range(epochs):\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Compute boundary loss: (predicted values from PINN - ground truth)^2\n",
    "        u_left = pinn(time_point_left)  # at t = 0\n",
    "        loss1_initial = (torch.squeeze(u_left) - u_first)**2  \n",
    "        \n",
    "        u_right = pinn(time_point_right)  # at t = end\n",
    "        loss1_final = (torch.squeeze(u_right) - u_last)**2  \n",
    "        \n",
    "        # loss for time derivative at the initial condition\n",
    "        dudt_left = torch.autograd.grad(u_left, time_point_left, torch.ones_like(u_left), create_graph=True)[0]\n",
    "        loss_deriv = (torch.squeeze(dudt_left) - du_first)**2\n",
    "        \n",
    "        # Physics loss: differential equation with input incorporated\n",
    "        u_physics = pinn(t_physics)  # Evaluate PINN at physics points\n",
    "        dudt_physics = torch.autograd.grad(u_physics, t_physics, torch.ones_like(u_physics), create_graph=True)[0]\n",
    "        loss_physics = torch.mean((dudt_physics + u_physics / (R * C) - v_input_interp / (R * C))**2)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = lambda_boundary * (loss1_initial + loss1_final) + lambda_deriv * loss_deriv + lambda_physics * loss_physics\n",
    "        loss.backward()  \n",
    "        optimiser.step()  \n",
    "        \n",
    "        # Plot the result during training\n",
    "        if i % 20000 == 0:\n",
    "            u_test = pinn(t_test).detach()\n",
    "            plt.figure(figsize=(6, 2.5))\n",
    "            plt.scatter(t_physics.detach()[:, 0], torch.zeros_like(t_physics)[:, 0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
    "            plt.scatter(time_point_left.detach()[:, 0], torch.zeros_like(time_point_left)[:, 0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
    "            plt.plot(t_test[:, 0], u_exact[:, 0], label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "            plt.plot(t_test[:, 0], u_test[:, 0], label=\"PINN solution\", color=\"tab:green\")\n",
    "            plt.title(f\"Training step {i}\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    return u_test, loss, pinn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T08:44:28.817877Z",
     "iopub.status.busy": "2024-10-09T08:44:28.817463Z",
     "iopub.status.idle": "2024-10-09T08:44:28.823482Z",
     "shell.execute_reply": "2024-10-09T08:44:28.822577Z",
     "shell.execute_reply.started": "2024-10-09T08:44:28.817834Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(str):\n",
    "\n",
    "    '''Save the model with annotation of your choice, to your default folder'''\n",
    "    output_model_file = '/kaggle/working/RC_PINN_'+str+'.pt'\n",
    "    \n",
    "    model_to_save = FCN\n",
    "    torch.save(model_to_save, output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:20:20.656980Z",
     "iopub.status.busy": "2024-10-09T09:20:20.656594Z",
     "iopub.status.idle": "2024-10-09T09:20:20.666350Z",
     "shell.execute_reply": "2024-10-09T09:20:20.665355Z",
     "shell.execute_reply.started": "2024-10-09T09:20:20.656945Z"
    }
   },
   "outputs": [],
   "source": [
    "def RAW_solve_train_objective(train_dict, ramp_dict, initial_conditions, lumped_elements):\n",
    "\n",
    "    '''An end-to-end function for deployment:\n",
    "    Inputs: ramp_dict --> parameters to define the input ramp function\n",
    "            initial_conditions --> initial conditions for solving the ODE equation\n",
    "            train_dict --> hyperparameters for the training process\n",
    "            \n",
    "    returns: predicted voltage across capacitor'''\n",
    "\n",
    "    # solve_ode: retrieve Ground truth for voltage across capacitor, dvdt, and input ramp function (used later to interploate the function in 'train_model')\n",
    "    Vc, DVDT, Vin_ramp, _ = solve_ode(ramp_dict, initial_conditions, lumped_elements, plot = True)\n",
    "\n",
    "    # extract boundaries to compute the boundary loss in 'train_model'\n",
    "    boundaries = extract_boundaries(Vc, DVDT)\n",
    "\n",
    "    # compute and retrieve the predicted values from the training process\n",
    "    u_pred, loss, pinn = train_model(train_dict[\"lr\"], lumped_elements, boundaries, Vin_ramp, Vc, train_dict[\"lambda_boundary\"], train_dict[\"lambda_deriv\"], \n",
    "                                     train_dict[\"lambda_physics\"],train_dict[\"epochs\"], int(train_dict[\"physics_points\"]), int(train_dict[\"n_hidden\"]), int(train_dict[\"n_layers\"]), \n",
    "                                     ramp_dict[\"repetitions\"], ramp_dict[\"T\"], ramp_dict[\"time_points\"])\n",
    "\n",
    "    # save the model\n",
    "    #save_model(str)\n",
    "    return {'loss': loss,\n",
    "            'status': STATUS_OK,\n",
    "            'model': pinn,\n",
    "            'params': train_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:20:39.363338Z",
     "iopub.status.busy": "2024-10-09T09:20:39.362940Z",
     "iopub.status.idle": "2024-10-09T09:20:39.368400Z",
     "shell.execute_reply": "2024-10-09T09:20:39.367232Z",
     "shell.execute_reply.started": "2024-10-09T09:20:39.363282Z"
    }
   },
   "outputs": [],
   "source": [
    "save_train_objective = partial(RAW_solve_train_objective, \n",
    "                              ramp_dict = ramp_dict,\n",
    "                              initial_conditions = initial_conditions,\n",
    "                              lumped_elements = lumped_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:20:41.528261Z",
     "iopub.status.busy": "2024-10-09T09:20:41.527626Z"
    }
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=save_train_objective,\n",
    "    space=train_dict,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:10:39.458881Z",
     "iopub.status.busy": "2024-10-09T09:10:39.458491Z",
     "iopub.status.idle": "2024-10-09T09:10:39.466831Z",
     "shell.execute_reply": "2024-10-09T09:10:39.465761Z",
     "shell.execute_reply.started": "2024-10-09T09:10:39.458846Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model('hyperOpt_attempt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:12:32.929017Z",
     "iopub.status.busy": "2024-10-09T09:12:32.928614Z",
     "iopub.status.idle": "2024-10-09T09:12:32.935114Z",
     "shell.execute_reply": "2024-10-09T09:12:32.934041Z",
     "shell.execute_reply.started": "2024-10-09T09:12:32.928982Z"
    }
   },
   "outputs": [],
   "source": [
    "strin = 'attempt1'\n",
    "try: \n",
    "\tgeeky_file = open('best_parameters'+strin+'.txt', 'a') \n",
    "\tgeeky_file.write(str(best_params)) \n",
    "\tgeeky_file.close() \n",
    "\n",
    "except: \n",
    "\tprint(\"Unable to append to file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-09T09:18:26.775604Z",
     "iopub.status.busy": "2024-10-09T09:18:26.775190Z",
     "iopub.status.idle": "2024-10-09T09:18:26.780836Z",
     "shell.execute_reply": "2024-10-09T09:18:26.779906Z",
     "shell.execute_reply.started": "2024-10-09T09:18:26.775569Z"
    }
   },
   "outputs": [],
   "source": [
    "try: print(best_params)\n",
    "\n",
    "except: print('best_params not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
